install.packages("KernSmooth")
library(KernSmooth)
x <- list(a=1:5, b=6:10)
lapply(x, mean)
mean(1:5)
mean(6:10)
x
x <- list(a = matrix(1:4, 2, 2), b = matrix(1:6, 3,2))
x
lapply(x, function(elt), elt[,1])
lapply(x, function(elt) elt[,1])
lapply(x, function(A) A[,1])
?lapply
lapply(x, function(A) A*2)
lapply(x, function(A) A+5)
lapply(x, function(A) A[,1]*2)
lapply(x, function(A) A)
q()
mapply(rep, 1:4, 4:!)
mapply(rep, 1:4, 4:1)
mapply(rep, 1:4, 10:1)
q()
library(datasets)
data(iris)
tapply(iris$Sepal.Length, iris$Species, mean)
tapply(iris$Sepal.Length, iris$Species, virginica, mean)
tapply(iris$Sepal.Length, iris$Species= "virginica", mean)
sapply(split(iris$Sepal.Length, iris$Species), mean)
with(mtcars, tapply(mpg, cyl, mean))
sapply(split(mtcars$mpg, mtcars$cyl), mean)
?with
with(mtcars, mean())
?mtcars
tapply(mtcars$hp, mtcars$cyl, mean)
q()
install.packages("swirl")
packageVersion("swirl")
library(swirl)
swirl()
5+7
x<-5+7
x
y<-x-3
y
z<-c(1.1, 9,3.14)
?c
z
c(z,555,z)
z*2+100
my_sqrt<-sqr(z-1)
my_sqrt<-sqrt(z-1)
my_sqrt
my_div<-z/my_sqrt
my_div
c(1,2,3,4)+c(0,10)
c(1,2,3,4)+c(0,10,100)
z*2+1000
my_div
getwd()
ls()
x<-9
ls()
list.files()
?list.files
args(list.files)
old.dir <- getwd()
dir.create(testdir)
?dir.create
dir.create("/", "testdir")
dir.create("testdir")
setwd("testdir")
file.create("mytest.R")
ls("testdir")
ls(testdir)
ls()
list.files()
file.exists()
file.exists("mytest.R")
file.info("mytest.R")
file.rename("mytest.R", "mytest2.R")
file.copy("mytest2.R")
?file.copy
file.copy("mytest2.R", "mytest3.R")
file.path("mytest3.R")
?file.path
file.path("folder1", "folder2")
?dir.create
dir.create("testdir2/testdir3", recursive = true)
dir.create("testdir2/testdir2", recursive = TRUE)
dir.create(file.path('testdir2', 'testdir3'), recursive = TRUE)
setwd(old.dir)
unlink("testdir", recursive = FALSE)
unlink("testdir", recursive =  TRUE)
1:20
pi:10
15:1
?`:`
seq(1:20)
seq(1:20)
seq(1,20)
seq(0,10, by=0.5)
seq(5,10, length=30 )
my_seq<- seq(5,10,length=30)
length(my_seq)
1:length(my_seq)
seq(along.with=my_seq)
seq_along(my_seq)
rep(0, times=40)
rep(c(0,1,2), times=10)
rep(c(0,1,2), each=10)
num_vect <-c(0.5, 55,-10, 6)
tf <- if(num_vect<1, TRUE, FALSE)
tf <- c("num_vect" is less than 1)
tf <- c("num_vect is less than 1")
tf <- num_vect<1
tf
num_vect >=6
my_char<-("My", "name", "is")
my_char<-c("My", "name", "is")
my_char
paste(my_char, collapse = "")
paste(my_char, collapse = " ")
my_name<-c(my_char, "Tatyana")
my_name
paste(my_name, collapse = " ")
paste("Hello", "world!", sep=" ")
paste(1:3, c("X", "Y", "Z"), sep="")
paste(LETTERS, 1:4, sep= "-")
x<-c(44,NA,5,NA)
x*3
y<-rnorm(1000)
z<-rep(NA, 1000)
my_data<-sample(c(y,z), 100)
my_na <-is.na(my_data)
my_na
my_data == NA
sum(my_na)
my_data
0/0
Inf-Inf
x
x[1:10]
x[is.na(x)]
y<- x[!is.na(x)]
y
y[y>0]
x[x>0]
x[!is.na(x) & x>0]
x[c(3,5,7)]
x[0]
x[3000]
x[c(-2,-10)]
x[-c(2,10)]
vect <- c(foo=11, bar = 2, norf = NA)
vect
names(vect)
vect2 <-c(11,2,NA)
names(vect2)<-c("foo", "bar", "norf")
identical(vect, vect2)
vect["bar"]
vect[c("foo", "bar")]
my_vector <- 1:20
my_vector
dim(my_vector)
length(my_vector)
dim(my_vector)<-c(4,5)
dimi(my_vector)
dim(my_vector)
attributes(my_vector)
my_vector
class(my_vector)
my_matrix<-my_vector
?matrix
my_matrix2 <- matrix(1:20, 4,5)
identical(my_matrix, my_matrix2)
patients <-c("Bill", "Gina", "Kelly", "Sean")
cbind(patients, my_matrix)
my_data<-data.frame(patients, my_matrix)
my_data
class(my_data)
c("patient", "age", "weight", "bp", "rating", "test")
cnames<-c("patient", "age", "weight", "bp", "rating", "test")
?colnames
colnames(my_data)<-cnames
my_data
TRUE==TRUE
(FALSE == TRUE) == FALSE
6==7
6>7
6<7
10<=10
5!=7
5 != 7
! 5==7
FALSE & FALSE
TRUE & c(TRUE, FALSE, FALSE)
TRUE && c(TRUE, FALSE, FALSE)
TRUE | c(TRUE, FALSE, FALSE)
TRUE || c(TRUE, FALSE, FALSE)
5 > 8 || 6 != 8 && 4 > 3.9
FALSE || TRUE
TRUE || FASLE || FALSE
FALSE && 6 >= 6 || 7 >= 8 || 50 <= 49.5
FALSE && 6 >= 6
FALSE && TRUE
FALSE & TRUE
FALSE | TRUE
isTRUE(6>4)
identical('twins', 'twins')
xor(5 == 6, !FALSE)
ints<-sample(10)
ints
ints>5
which(intx, > 7)
?which
which(ints>7)
any(ints>0)
any(ints<0)
all(ints>0)
sys.date()
Sys.Date()
mean(c(2,4,5))
submit()
boring_function('My first function')
boring_function('My first function!')
boring_function()
boring_function
submit
submit()
my_mean(c(4,5,10))
submit()
submit()
submit()
remainder(5)
remainder(11, 5)
remainder(divisor = 11, num = 5)
remainder(4, div = 2)
args(remainder)
submit()
evaluate(sd, c(1.4, 3.6, 7.9, 8.8))
evaluate(function(x){x+1}, 6)
evaluate(function(x) {x[1]}, c(8, 4, 0))
evaluate(function(x) {x[length(x)]}, c(8, 4, 0))
?paste
paste("Programming", "is", "fun!")
submit()
submit()
telegram("bang")
submit()
telegram("boom")
View(telegram)
submit()
mad_libs(palce = "Kiev", adjective = "at", noun = "boom")
mad_libs(palce = "Kiev", adjective = "at", noun = "boom")
mad_libs(palce = "Kiev", adjective = "at", noun = "boom")
mad_libs <- function(...){
# Do your argument unpacking here!
argms <- list (...)
place <- argms[["place"]]
adjective <- argms[["adjective"]]
noun <- argms[["noun"]]
# Don't modify any code below this comment.
# Notice the variables you'll need to create in order for the code below to
# be functional!
print(argms["place"])
}
mad_libs(palce = "Kiev", adjective = "at", noun = "boom")
submit()
"I" %p% "love" %p% "R"
"I"%p%"love"%p%"R"
info()
'I'%p%'love'%p%'R'
"I"%p%"love"
I"%p%"love"%p%"R!"
"I"%p%"love"%p%"R!"
Sys.Date()
mean(c(2, 4, 5))
submit()
boring_function("My first function!")
boring_function
submit()
my_mean(c(4, 5, 10))
submit()
submit()
remainder(5)
remainder(11, 5)
remainder(divisor = 11, num = 5)
remainder(4, div = 2)
args(remainder)
submit()
evaluate(c(1.4, 3.6, 7.9, 8.8))
eval(sd, c(1.4, 3.6, 7.9, 8.8))
evaluate(sd, c(1.4, 3.6, 7.9, 8.8))
evaluate(function(x){x+1}, 6)
evaluate(function(x) {x[1]}, c(8, 4, 0))
evaluate(function(x) {x[lenght(x)]}, c(8, 4, 0))
evaluate(function(x) {x[length(x)]}, c(8, 4, 0))
?paste
paste("Programming", "is", "fun!")
sub()
submit()
telegram("boo")
submit()
submit()
submit()
submit()
mad_libs("poo", "bb", "b")
submit()
"I"%p%"love"%p%"R!"
q()
df<-data.frame("a1" =c("a","a","a",b","b","c"), "a2"=c(1,2,3,4,5,6,7), "a3"=c(8,9,10,11,12,13,14) )
df<-data.frame("a1" =c("a","a","a","b","b","c"), "a2"=c(1,2,3,4,5,6,7), "a3"=c(8,9,10,11,12,13,14) )
df<-data.frame("a1" =c("a","a","a","b","b","c","c"), "a2"=c(1,2,3,4,5,6,7), "a3"=c(8,9,10,11,12,13,14) )
df
library(dplyr)
install.packages("dplyr")
install.packages("dplyr")
load(dplyr)
library("dplyr")
group_by(df, a1)
xtabs(~a1, data=df)
xtabs(+a1, data=df)
xtabs(a1, data=df)
?group_by
group_by(df,a1)
group_by(df,a2)
group_by(df,a3)
group_by(df,"a")
load(mtcars)
load("mtcars")
group_by(mtcars, cyl)
head(mtcars)
quit()
setwd("C:/Users/Tatiana Lysenko/Desktop/Weekly Report Automated")
source("WR.R")
WeeklyRecrRport()
?read.table
?make.names
#1 Merges the training and the test sets to create one data set.
#2 Extracts only the measurements on the mean and standard deviation for each measurement.
#3 Uses descriptive activity names to name the activities in the data set
#4 Appropriately labels the data set with descriptive variable names.
#5 From the data set in step 4, creates a second, independent tidy data set with the average of each variable for each activity and each subject.
install.packages("dplyr")
library("dplyr")
library("reshape2")
library(data.table)
ziplink <-"https://d396qusza40orc.cloudfront.net/getdata%2Fprojectfiles%2FUCI%20HAR%20Dataset.zip"
fpath <- file.path(getwd(), "seonsros.zip")
unzip(fpath, exdir = getwd())
download.file(ziplink, fpath)
unzip(fpath, exdir = getwd())
setwd("C:/Users/Tatiana Lysenko/Desktop/DS/UCI HAR Dataset")
#read the test and training datasets
feature_test<- read.table("./test/X_test.txt", header = FALSE)
feature_train <- read.table("./train/X_train.txt", header = FALSE)
feature_subject <- read.table("./train/subject_train.txt", header = FALSE)
activity_train <- read.table("./train/y_train.txt", header = FALSE)
activity_subject<- read.table("./test/subject_test.txt", header = FALSE)
activity_test <- read.table("./test/y_test.txt", header = FALSE)
feature_names <-read.table("./features.txt", header = FALSE, stringsAsFactors = FALSE)[,2]
activity_labels <- read.table("./activity_labels.txt", header = FALSE, stringsAsFactors = FALSE)[,2]
### STEP 1 Merges the training and the test sets to create one data set.
activity <- rbind(activity_test, activity_train)
feature <-rbind(feature_test, feature_train)
subject <- rbind(activity_subject, activity_train)
rm(activity_test, activity_train, feature_test, feature_train, activity_subject, feature_subject)
colnames(feature)<-feature_names
### STEP 2 Extract only the measurements on the mean and standard deviation for each measurement.
feature_indx <- grepl("mean|std", feature_names, ignore.case = TRUE)
feature = feature[,feature_indx]
### STEP 3 Uses descriptive activity names to name the activities in the data set
colnames(activity) <- "Activity"
colnames(subject)<- "Subject"
FinalDataSet <- cbind(activity, subject, feature)
FinalDataSet$Activity = activity_labels[FinalDataSet$Activity]
### STEP 4 Appropriately labels the data set with descriptive variable names.
### STEP 5 From the data set in step 4, creates a second, independent tidy data set with the
# average of each variable for each activity and each subject.
melteddata <- melt(FinalDataSet, id.vars =c("Activity","Subject"))
meandata <- dcast(melteddata, Activity +Subject~ variable , mean)
class(names(FinalDataSet))
names(FinalDataSet)[1]
names(FinalDataSet)[2]
names(FinalDataSet)[3]
names(FinalDataSet)
names(FinalDataSet)<-gsub("Acc", "Acceleration", names(FinalDataSet))
names(FinalDataSet)[83]
fpath
write.table(meandata, file=fpath(getwd(), "finaldata.txt"))
write.table(meandata, file=file.path(getwd(), "finaldata.txt"))
#1 Merges the training and the test sets to create one data set.
#2 Extracts only the measurements on the mean and standard deviation for each measurement.
#3 Uses descriptive activity names to name the activities in the data set
#4 Appropriately labels the data set with descriptive variable names.
#5 From the data set in step 4, creates a second, independent tidy data set with the average of each variable for each activity and each subject.
library("dplyr")
library("reshape2")
library(data.table)
ziplink <-"https://d396qusza40orc.cloudfront.net/getdata%2Fprojectfiles%2FUCI%20HAR%20Dataset.zip"
setwd("C:/Users/Tatiana Lysenko/Desktop/DS/UCI HAR Dataset")
fpath <- file.path(getwd(), "seonsros.zip")
unzip(fpath, exdir = getwd())
download.file(ziplink, fpath)
unzip(fpath, exdir = getwd())
#read the test and training datasets
feature_test<- read.table("./test/X_test.txt", header = FALSE)
feature_train <- read.table("./train/X_train.txt", header = FALSE)
feature_subject <- read.table("./train/subject_train.txt", header = FALSE)
activity_train <- read.table("./train/y_train.txt", header = FALSE)
activity_subject<- read.table("./test/subject_test.txt", header = FALSE)
activity_test <- read.table("./test/y_test.txt", header = FALSE)
feature_names <-read.table("./features.txt", header = FALSE, stringsAsFactors = FALSE)[,2]
activity_labels <- read.table("./activity_labels.txt", header = FALSE, stringsAsFactors = FALSE)[,2]
### STEP 1 Merges the training and the test sets to create one data set.
activity <- rbind(activity_test, activity_train)
feature <-rbind(feature_test, feature_train)
subject <- rbind(activity_subject, activity_train)
#removing unused data
rm(activity_test, activity_train, feature_test, feature_train, activity_subject, feature_subject)
colnames(feature)<-feature_names
### STEP 2 Extract only the measurements on the mean and standard deviation for each measurement.
feature_indx <- grepl("mean|std", feature_names, ignore.case = TRUE)
feature = feature[,feature_indx]
### STEP 3 Uses descriptive activity names to name the activities in the data set
colnames(activity) <- "Activity"
colnames(subject)<- "Subject"
maindataset <- cbind(activity, subject, feature)
dataset$Activity = activity_labels[maindataset$Activity]
### STEP 4 Appropriately labels the data set with descriptive variable names.
names(maindataset)<-gsub('Acc', "Acceleration", names(maindataset))
names(maindataset)<-gsub('GyroJerk',"AngularAcceleration", names(maindataset))
names(maindataset)<-gsub('Gyro',"AngularSpeed", names(maindataset))
names(maindataset)<-gsub('Mag',"Magnitude", names(maindataset))
names(maindataset)<-gsub('\\.std',".StandardDeviation", names(maindataset))
names(maindataset)<-gsub('Freq\\.',"Frequency.", names(maindataset))
names(maindataset)<-gsub('Freq$',"Frequency", names(maindataset))
names(maindataset)<-gsub('^f',"FrequencyDomain.", names(maindataset))
names(maindataset)<-gsub('^t',"TimeDomain.", names(maindataset))
### STEP 5 From the data set in step 4, creates a second, independent tidy data set with the
# average of each variable for each activity and each subject.
melteddata <- melt(maindataset, id.vars =c("Activity","Subject"))
meandata <- dcast(melteddata, Activity +Subject~ variable , mean)
write.table(meandata, file=file.path(getwd(), "finaldata.txt"))
View(meandata)
names(maindataset)
ziplink <-"https://d396qusza40orc.cloudfront.net/getdata%2Fprojectfiles%2FUCI%20HAR%20Dataset.zip"
setwd("C:/Users/Tatiana Lysenko/Desktop/DS/UCI HAR Dataset")
fpath <- file.path(getwd(), "seonsros.zip")
unzip(fpath, exdir = getwd())
download.file(ziplink, fpath)
unzip(fpath, exdir = getwd())
#read the test and training datasets
feature_test<- read.table("./test/X_test.txt", header = FALSE)
feature_train <- read.table("./train/X_train.txt", header = FALSE)
feature_subject <- read.table("./train/subject_train.txt", header = FALSE)
activity_train <- read.table("./train/y_train.txt", header = FALSE)
activity_subject<- read.table("./test/subject_test.txt", header = FALSE)
activity_test <- read.table("./test/y_test.txt", header = FALSE)
feature_names <-read.table("./features.txt", header = FALSE, stringsAsFactors = FALSE)[,2]
activity_labels <- read.table("./activity_labels.txt", header = FALSE, stringsAsFactors = FALSE)[,2]
### STEP 1 Merges the training and the test sets to create one data set.
activity <- rbind(activity_test, activity_train)
feature <-rbind(feature_test, feature_train)
subject <- rbind(activity_subject, activity_train)
#removing unused data
rm(activity_test, activity_train, feature_test, feature_train, activity_subject, feature_subject)
colnames(feature)<-feature_names
### STEP 2 Extract only the measurements on the mean and standard deviation for each measurement.
feature_indx <- grepl("mean|std", feature_names, ignore.case = TRUE)
feature = feature[,feature_indx]
### STEP 3 Uses descriptive activity names to name the activities in the data set
colnames(activity) <- "Activity"
colnames(subject)<- "Subject"
maindataset <- cbind(activity, subject, feature)
dataset$Activity = activity_labels[maindataset$Activity]
### STEP 4 Appropriately labels the data set with descriptive variable names.
oldnames <-names(maindataset)
names(maindataset)<-gsub('Acc', "Acceleration", names(maindataset))
names(maindataset)<-gsub('GyroJerk',"AngularAcceleration", names(maindataset))
names(maindataset)<-gsub('Gyro',"AngularSpeed", names(maindataset))
names(maindataset)<-gsub('Mag',"Magnitude", names(maindataset))
names(maindataset)<-gsub('\\.std',".StandardDeviation", names(maindataset))
names(maindataset)<-gsub('Freq\\.',"Frequency.", names(maindataset))
names(maindataset)<-gsub('Freq$',"Frequency", names(maindataset))
names(maindataset)<-gsub('^f',"FrequencyDomain.", names(maindataset))
names(maindataset)<-gsub('^t',"TimeDomain.", names(maindataset))
### STEP 5 From the data set in step 4, creates a second, independent tidy data set with the
# average of each variable for each activity and each subject.
melteddata <- melt(maindataset, id.vars =c("Activity","Subject"))
meandata <- dcast(melteddata, Activity +Subject~ variable , mean)
write.table(meandata, file=file.path(getwd(), "finaldata.txt"))
quit()
